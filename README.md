# Tumor Classification using GANs

This project explores the use of **Generative Adversarial Networks (GANs)** for augmenting brain MRI datasets, specifically using **Deep Convolutional GAN (DCGAN)** architecture to generate synthetic tumor and normal MRI images. These generated images were used to enhance the classification performance of deep learning models, including **ResNet** and **MobileNet**, for the task of classifying brain tumor images.

## Project Overview

The core goal of this project is to improve the accuracy of deep learning models in classifying tumor images by leveraging GAN-generated data. By using real data for validation and GAN-generated data for training, we ensure that the synthetic images approximate the distribution of real MRI images, which aids the model in learning critical features.

### Key Points:
- **Data Generation**: DCGAN is used to generate synthetic tumor and normal MRI images from random noise.
- **Model Architecture**: The project employs a **Generator-Discriminator** setup, where the Generator creates realistic images, and the Discriminator differentiates between real and generated images.
- **Classification**: We used **ResNet152V2** and **MobileNetV2** for classifying the real MRI images into tumor and non-tumor. The models are trained on the images generated by DCGAN, which shows that the images generated are close to the actual MRI images.

### Results:
- The **ResNet** model achieved an accuracy of **72.19%**, demonstrating the potential of GAN-based data augmentation in medical image classification tasks.
- The project demonstrates that GANs can be explored for improving performance in medical imaging, specifically in brain tumor classification.

## Model Description

- **Generator**: The generator network is a deep convolutional model designed to create synthetic images from random noise. It uses transposed convolution layers, batch normalization, and LeakyReLU activation functions to upsample the input noise into realistic images.
  
- **Discriminator**: A convolutional neural network used to classify images as real (from the dataset) or fake (generated by the Generator). It uses multiple convolutional layers with LeakyReLU activation, dropout, and binary cross-entropy loss for training.

- **Training Process**: The models are trained using the DCGAN architecture, with the Generator and Discriminator updated iteratively for each epoch. Every 100 epochs, generated images are displayed for evaluation.

## Performance and Future Work

The accuracy achieved by the **ResNet** model is promising, but further improvements can be made with more complex models and longer training durations. The current results were obtained without access to high-end GPUs, which limited the ability to train more complex models. **Exploring deeper networks** and running models for **more epochs** could yield better results. Enhanced hardware access would allow us to experiment with larger, more intricate models and more data, likely improving the performance of the generated images.

## Report
A detailed report outlining the project, methodology, results, and analysis is available in the included PDF document.

## Licence
This project is licensed under the MIT License - see the LICENSE file for details.
